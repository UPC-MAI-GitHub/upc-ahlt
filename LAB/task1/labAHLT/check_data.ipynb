{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Baseline NERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if the name contains special symbols \n",
    "def check_chemical_name(some_text:str) -> str:\n",
    "    \"\"\"Function which checks whether a text contains numbers, special characters \n",
    "    which are similar to chemical names.\"\"\"\n",
    "    ## naming binary molecules \n",
    "    greek_prefix = [\"hemi\",\"mono\",\n",
    "                    \"di\",\"tri\",\n",
    "                    \"tetra\",\"penta\",\n",
    "                    \"hexa\",\"hepta\",\n",
    "                    \"octa\",\"nona\",\n",
    "                    \"deca\"]\n",
    "    ## Metallic Names \n",
    "    metal_names = [\"cuprous\",\"cupric\",\n",
    "                   \"ferrous\",\"ferric\",\n",
    "                   \"mercurous\",\"mercuric\",\n",
    "                   \"stannous\",\"stannic\"]\n",
    "    ## Non-metal suffixes \n",
    "    non_metal_names = [\"ide\"]\n",
    "    ## Others\n",
    "    other_names = ['ite','ate']\n",
    "    ## Bonds \n",
    "    bonds = [\"ene\",'yne']\n",
    "    ## functional groups \n",
    "    func_groups = [\n",
    "                   \"carboxy\",\"carbamoyl\",\n",
    "                   \"chloroformyl\",\"hydroxy\",\n",
    "                   \"formyl\",\"oxo\",\"alkyl\",\n",
    "                   \"alkoxy\",\"epoxy\",\"halo\",\n",
    "                   \"amine\",\"cyano\",\"nitro\",\"nitroso\",\n",
    "                   \"azo\",\"sulpho\",\"alkyl thio\",\"mercapto\"\n",
    "                   ]\n",
    "    ## functional group suffixes \n",
    "    func_g_suffix = [\n",
    "                    \"oic\",\"amide\",\"oyl\",\"chloride\",\"acid\",\n",
    "                    \"ol\",\"al\",\"one\",\"carboxylate\",\"amine\",\"nitrile\",\n",
    "                    \"sulphonic\",\"thiol\"\n",
    "                    ]\n",
    "    ## other names \n",
    "    other_names2 = [\"meth\",\"eth\",\"methyl\",\"ethyl\",\"yl\"]\n",
    "    ## bring them all together \n",
    "    tmp_list = [greek_prefix,\n",
    "                metal_names,non_metal_names,\n",
    "                other_names,\n",
    "                bonds,\n",
    "                func_groups,\n",
    "                func_g_suffix,other_names2]\n",
    "    ## merging & making into a set\n",
    "    full_list = set(sum(tmp_list, []))\n",
    "    ## now we can check if it starts with a number ? \n",
    "    starts_with_digit = some_text[:1].isdigit()\n",
    "    ## contains numbers?\n",
    "    contains_number = any(char.isdigit() for char in some_text)\n",
    "    ## does it contain hyphens?\n",
    "    contain_hyphen = (\"-\" in some_text)\n",
    "    ## contains parenthesis\n",
    "    contain_parenthesis = (\"(\" in some_text) and (\")\" in some_text)\n",
    "    ## does it contain a comma?\n",
    "    contain_comma = (\",\" in some_text)\n",
    "    #return (full_list, starts_with_digit, contain_hyphen, contain_parenthesis,contain_comma)\n",
    "    ## iterate over our set \n",
    "    cnt = sum([1 for x in full_list if x in some_text])\n",
    "    #print(cnt)\n",
    "    ## check if the\n",
    "    val = (starts_with_digit+contains_number+contain_hyphen+contain_parenthesis+contain_comma)\n",
    "    #print(f\"Total Rules out of 5 which apply: {val}\")\n",
    "    ## contains number + hyphen + parenthesis? --> definetly a drug!\n",
    "    if contains_number and contain_hyphen and contain_parenthesis:\n",
    "        #return \"drug\"\n",
    "        print(\"drug\")\n",
    "    ## number and comma? also a drug \n",
    "    if contains_number and contain_comma:\n",
    "        #return \"drug\"\n",
    "        print(\"drug\")\n",
    "    ## if the value of our rules is greater than 3, and there is at least \n",
    "    ## one occurence of a \"chemical suffix\", return drug\n",
    "    if val > 3 and cnt>1: \n",
    "        #return \"drug\"\n",
    "        print(\"drug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug\n",
      "drug\n",
      "drug\n",
      "drug\n",
      "drug\n",
      "drug\n"
     ]
    }
   ],
   "source": [
    "## testing with a random drug name \n",
    "txt = \"1,2-betahydroxy-2,3-oleic acid\"\n",
    "check_chemical_name(txt)\n",
    "l = list(map(check_chemical_name, drug_name)) ## kinda sucks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse\n",
    "import glob \n",
    "\n",
    "DATA_PATH = \"./data\"\n",
    "file_list = glob.glob(DATA_PATH+\"/*/*.xml\")\n",
    "\n",
    "## parse all the trees \n",
    "parsed_trees = list(map(parse, file_list))\n",
    "elements = list(map(lambda x: x.getElementsByTagName(\"entity\"),parsed_trees))\n",
    "\n",
    "## get the elements \n",
    "elements = list(map(lambda x: x.getElementsByTagName(\"entity\"),parsed_trees))\n",
    "## get their values \n",
    "drug_type = [x[0].attributes['type'].value for x in elements if len(x)>1]\n",
    "drug_name = [x[0].attributes['text'].value for x in elements if len(x)>1]\n",
    "## zip together \n",
    "d = dict(zip(drug_name, drug_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_drug_names(list_of_files:list) -> dict:\n",
    "    ## parse all the trees \n",
    "    parsed_trees = list(map(parse, list_of_files))\n",
    "    ## get the elements \n",
    "    elements = list(map(lambda x: x.getElementsByTagName(\"entity\"),parsed_trees))\n",
    "    ## get their values \n",
    "    drug_type = [x[0].attributes['type'].value for x in elements if len(x)>1]\n",
    "    drug_name = [x[0].attributes['text'].value for x in elements if len(x)>1]\n",
    "    ## zip together \n",
    "    d = dict(zip(drug_name, drug_type))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_all_drug_names(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>thimerosal</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>ruthenium red</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>resveratrol</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>precocene I</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>piperine</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>picrotoxin</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>neurotensin</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>hemantane</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>gliftor</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>ginsenosides</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>coumaphos</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>contortrostatin</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cerulein</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>buforin II</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>arsenate</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>angiotensin</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Thiolated carboxymethylcellulose</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Paricalcitol</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>N-allylnormetazocine</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Misonidazole</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>MPTP</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>KRM-1648</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Jacalin</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Ganoderma lucidum extract</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>DZNep</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>DCG-IV</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Clostridium difficile toxin A</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>CRM197</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAV2</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6MNA</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18-Methoxycoronaridine</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16,16-dimethylprostaglandin E2</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-methyl-4-phenyl-1,2,5,6-tetrahydropyridine</td>\n",
       "      <td>drug_n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comp    type\n",
       "673                                    thimerosal  drug_n\n",
       "653                                 ruthenium red  drug_n\n",
       "650                                   resveratrol  drug_n\n",
       "639                                   precocene I  drug_n\n",
       "638                                      piperine  drug_n\n",
       "636                                    picrotoxin  drug_n\n",
       "619                                   neurotensin  drug_n\n",
       "572                                     hemantane  drug_n\n",
       "567                                       gliftor  drug_n\n",
       "566                                  ginsenosides  drug_n\n",
       "507                                     coumaphos  drug_n\n",
       "505                               contortrostatin  drug_n\n",
       "488                                      cerulein  drug_n\n",
       "468                                    buforin II  drug_n\n",
       "452                                      arsenate  drug_n\n",
       "432                                   angiotensin  drug_n\n",
       "372              Thiolated carboxymethylcellulose  drug_n\n",
       "308                                  Paricalcitol  drug_n\n",
       "274                          N-allylnormetazocine  drug_n\n",
       "268                                  Misonidazole  drug_n\n",
       "249                                          MPTP  drug_n\n",
       "223                                      KRM-1648  drug_n\n",
       "222                                       Jacalin  drug_n\n",
       "196                     Ganoderma lucidum extract  drug_n\n",
       "130                                         DZNep  drug_n\n",
       "122                                        DCG-IV  drug_n\n",
       "108                 Clostridium difficile toxin A  drug_n\n",
       "84                                         CRM197  drug_n\n",
       "6                                            AAV2  drug_n\n",
       "4                                            6MNA  drug_n\n",
       "2                          18-Methoxycoronaridine  drug_n\n",
       "1                  16,16-dimethylprostaglandin E2  drug_n\n",
       "0    1-methyl-4-phenyl-1,2,5,6-tetrahydropyridine  drug_n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.type == \"drug_n\"].sort_values(\"comp\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(d,index=[0]).T.reset_index()\n",
    "df.columns = ['comp',\"type\"]\n",
    "df.to_csv(\"./data/drugs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: ML NERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from os import listdir\n",
    "\n",
    "from xml.dom.minidom import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    offset = 0\n",
    "    tks = []\n",
    "    ## word_tokenize splits words, taking into account punctuations, numbers, etc.\n",
    "    for t in word_tokenize(txt):\n",
    "        ## keep track of the position where each token should appear, and\n",
    "        ## store that information with the token\n",
    "        offset = txt.find(t, offset)\n",
    "        tks.append((t, offset, offset+len(t)-1))\n",
    "        offset += len(t)\n",
    "\n",
    "    ## tks is a list of triples (word,start,end)\n",
    "    return tks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(token, spans) :\n",
    "   (_,start,end) = token\n",
    "   for (spanS,spanE,spanT) in spans :\n",
    "      if start==spanS and end<=spanE : return \"B-\"+spanT\n",
    "      elif start>=spanS and end<=spanE : return \"I-\"+spanT\n",
    "\n",
    "   return \"O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tokens:str) -> list:\n",
    "    \"\"\"Function to extract features from the \"\"\"\n",
    "    # for each token, generate list of features and add it to the result\n",
    "    result = []\n",
    "    for k in range(0,len(tokens)):\n",
    "        tokenFeatures = []\n",
    "        t = tokens[k][0]\n",
    "        ## so we can count capitals here\n",
    "        count_caps = str(any(char.isupper() for char in t))\n",
    "        all_caps = str(t.isupper())\n",
    "        t = t.lower()\n",
    "        ## Append the actual word \n",
    "        tokenFeatures.append(\"form=\"+t)\n",
    "        ## the suffixes\n",
    "        tokenFeatures.append(\"suf5=\"+t[-5:])\n",
    "        tokenFeatures.append(\"suf4=\"+t[-4:])\n",
    "        tokenFeatures.append(\"suf3=\"+t[-3:])\n",
    "        tokenFeatures.append(\"suf2=\"+t[-2:])\n",
    "        ## get the prefixes\n",
    "        tokenFeatures.append(\"pref5=\"+t[:5])\n",
    "        tokenFeatures.append(\"pref4=\"+t[:4])\n",
    "        tokenFeatures.append(\"pref3=\"+t[:3])\n",
    "        tokenFeatures.append(\"pref2=\"+t[:2])\n",
    "        ## Are there any numbers \n",
    "        tokenFeatures.append(\"CountNum=\"+str(any(char.isdigit() for char in t)))\n",
    "        ## Any capital \n",
    "        tokenFeatures.append(\"CountCaps=\"+count_caps)\n",
    "        tokenFeatures.append(\"AllCaps=\"+all_caps)\n",
    "        ## any hyphens? \n",
    "        tokenFeatures.append(\"Hyphen=\"+str((\"-\" in t)))\n",
    "        ## parenthesis\n",
    "        tokenFeatures.append(\"Parenth=\"+str((\"(\" and \")\" in t)))\n",
    "        ## previous word \n",
    "        if k>0 :\n",
    "            tPrev = tokens[k-1][0]\n",
    "            tokenFeatures.append(\"formPrev=\"+tPrev)\n",
    "            tokenFeatures.append(\"suf5Prev=\"+tPrev[-5:])\n",
    "            tokenFeatures.append(\"suf4Prev=\"+tPrev[-4:])\n",
    "            tokenFeatures.append(\"suf3Prev=\"+tPrev[-3:])\n",
    "            tokenFeatures.append(\"suf2Prev=\"+tPrev[-2:])\n",
    "        else :\n",
    "            tokenFeatures.append(\"BoS\")\n",
    "\n",
    "        ## next word \n",
    "        if k<len(tokens)-1 :\n",
    "            tNext = tokens[k+1][0]\n",
    "            tokenFeatures.append(\"formNext=\"+tNext)\n",
    "            tokenFeatures.append(\"suf5Next=\"+tNext[:5])\n",
    "            tokenFeatures.append(\"suf4Next=\"+tNext[:4])\n",
    "            tokenFeatures.append(\"suf3Next=\"+tNext[:3])\n",
    "            tokenFeatures.append(\"suf2Next=\"+tNext[:2])\n",
    "        else:\n",
    "            tokenFeatures.append(\"EoS\")\n",
    "        \n",
    "        ## Next word \n",
    "        if k<len(tokens)-2:\n",
    "            pass\n",
    "               \n",
    "        \n",
    "        result.append(tokenFeatures)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/Users/Eric/Documents/Uni/Msc/Courses/Sem2/AHLT/LAB/task1/labAHLT/data/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milk, milk products, and calcium-rich foods or drugs may impair the absorption of EMCYT.\n",
      "['form=milk', 'suf5=milk', 'suf4=milk', 'suf3=ilk', 'suf2=lk', 'pref5=milk', 'pref4=milk', 'pref3=mil', 'pref2=mi', 'CountNum=False', 'CountCaps=True', 'Hyphen=False', 'Parenth=False', 'BoS', 'formNext=,', 'suf5Next=,', 'suf4Next=,', 'suf3Next=,', 'suf2Next=,']\n",
      "['form=,', 'suf5=,', 'suf4=,', 'suf3=,', 'suf2=,', 'pref5=,', 'pref4=,', 'pref3=,', 'pref2=,', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=Milk', 'suf5Prev=Milk', 'suf4Prev=Milk', 'suf3Prev=ilk', 'suf2Prev=lk', 'formNext=milk', 'suf5Next=milk', 'suf4Next=milk', 'suf3Next=mil', 'suf2Next=mi']\n",
      "['form=milk', 'suf5=milk', 'suf4=milk', 'suf3=ilk', 'suf2=lk', 'pref5=milk', 'pref4=milk', 'pref3=mil', 'pref2=mi', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=,', 'suf5Prev=,', 'suf4Prev=,', 'suf3Prev=,', 'suf2Prev=,', 'formNext=products', 'suf5Next=produ', 'suf4Next=prod', 'suf3Next=pro', 'suf2Next=pr']\n",
      "['form=products', 'suf5=ducts', 'suf4=ucts', 'suf3=cts', 'suf2=ts', 'pref5=produ', 'pref4=prod', 'pref3=pro', 'pref2=pr', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=milk', 'suf5Prev=milk', 'suf4Prev=milk', 'suf3Prev=ilk', 'suf2Prev=lk', 'formNext=,', 'suf5Next=,', 'suf4Next=,', 'suf3Next=,', 'suf2Next=,']\n",
      "['form=,', 'suf5=,', 'suf4=,', 'suf3=,', 'suf2=,', 'pref5=,', 'pref4=,', 'pref3=,', 'pref2=,', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=products', 'suf5Prev=ducts', 'suf4Prev=ucts', 'suf3Prev=cts', 'suf2Prev=ts', 'formNext=and', 'suf5Next=and', 'suf4Next=and', 'suf3Next=and', 'suf2Next=an']\n",
      "['form=and', 'suf5=and', 'suf4=and', 'suf3=and', 'suf2=nd', 'pref5=and', 'pref4=and', 'pref3=and', 'pref2=an', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=,', 'suf5Prev=,', 'suf4Prev=,', 'suf3Prev=,', 'suf2Prev=,', 'formNext=calcium-rich', 'suf5Next=calci', 'suf4Next=calc', 'suf3Next=cal', 'suf2Next=ca']\n",
      "['form=calcium-rich', 'suf5=-rich', 'suf4=rich', 'suf3=ich', 'suf2=ch', 'pref5=calci', 'pref4=calc', 'pref3=cal', 'pref2=ca', 'CountNum=False', 'CountCaps=False', 'Hyphen=True', 'Parenth=False', 'formPrev=and', 'suf5Prev=and', 'suf4Prev=and', 'suf3Prev=and', 'suf2Prev=nd', 'formNext=foods', 'suf5Next=foods', 'suf4Next=food', 'suf3Next=foo', 'suf2Next=fo']\n",
      "['form=foods', 'suf5=foods', 'suf4=oods', 'suf3=ods', 'suf2=ds', 'pref5=foods', 'pref4=food', 'pref3=foo', 'pref2=fo', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=calcium-rich', 'suf5Prev=-rich', 'suf4Prev=rich', 'suf3Prev=ich', 'suf2Prev=ch', 'formNext=or', 'suf5Next=or', 'suf4Next=or', 'suf3Next=or', 'suf2Next=or']\n",
      "['form=or', 'suf5=or', 'suf4=or', 'suf3=or', 'suf2=or', 'pref5=or', 'pref4=or', 'pref3=or', 'pref2=or', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=foods', 'suf5Prev=foods', 'suf4Prev=oods', 'suf3Prev=ods', 'suf2Prev=ds', 'formNext=drugs', 'suf5Next=drugs', 'suf4Next=drug', 'suf3Next=dru', 'suf2Next=dr']\n",
      "['form=drugs', 'suf5=drugs', 'suf4=rugs', 'suf3=ugs', 'suf2=gs', 'pref5=drugs', 'pref4=drug', 'pref3=dru', 'pref2=dr', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=or', 'suf5Prev=or', 'suf4Prev=or', 'suf3Prev=or', 'suf2Prev=or', 'formNext=may', 'suf5Next=may', 'suf4Next=may', 'suf3Next=may', 'suf2Next=ma']\n",
      "['form=may', 'suf5=may', 'suf4=may', 'suf3=may', 'suf2=ay', 'pref5=may', 'pref4=may', 'pref3=may', 'pref2=ma', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=drugs', 'suf5Prev=drugs', 'suf4Prev=rugs', 'suf3Prev=ugs', 'suf2Prev=gs', 'formNext=impair', 'suf5Next=impai', 'suf4Next=impa', 'suf3Next=imp', 'suf2Next=im']\n",
      "['form=impair', 'suf5=mpair', 'suf4=pair', 'suf3=air', 'suf2=ir', 'pref5=impai', 'pref4=impa', 'pref3=imp', 'pref2=im', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=may', 'suf5Prev=may', 'suf4Prev=may', 'suf3Prev=may', 'suf2Prev=ay', 'formNext=the', 'suf5Next=the', 'suf4Next=the', 'suf3Next=the', 'suf2Next=th']\n",
      "['form=the', 'suf5=the', 'suf4=the', 'suf3=the', 'suf2=he', 'pref5=the', 'pref4=the', 'pref3=the', 'pref2=th', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=impair', 'suf5Prev=mpair', 'suf4Prev=pair', 'suf3Prev=air', 'suf2Prev=ir', 'formNext=absorption', 'suf5Next=absor', 'suf4Next=abso', 'suf3Next=abs', 'suf2Next=ab']\n",
      "['form=absorption', 'suf5=ption', 'suf4=tion', 'suf3=ion', 'suf2=on', 'pref5=absor', 'pref4=abso', 'pref3=abs', 'pref2=ab', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=the', 'suf5Prev=the', 'suf4Prev=the', 'suf3Prev=the', 'suf2Prev=he', 'formNext=of', 'suf5Next=of', 'suf4Next=of', 'suf3Next=of', 'suf2Next=of']\n",
      "['form=of', 'suf5=of', 'suf4=of', 'suf3=of', 'suf2=of', 'pref5=of', 'pref4=of', 'pref3=of', 'pref2=of', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=absorption', 'suf5Prev=ption', 'suf4Prev=tion', 'suf3Prev=ion', 'suf2Prev=on', 'formNext=EMCYT', 'suf5Next=EMCYT', 'suf4Next=EMCY', 'suf3Next=EMC', 'suf2Next=EM']\n",
      "['form=emcyt', 'suf5=emcyt', 'suf4=mcyt', 'suf3=cyt', 'suf2=yt', 'pref5=emcyt', 'pref4=emcy', 'pref3=emc', 'pref2=em', 'CountNum=False', 'CountCaps=True', 'Hyphen=False', 'Parenth=False', 'formPrev=of', 'suf5Prev=of', 'suf4Prev=of', 'suf3Prev=of', 'suf2Prev=of', 'formNext=.', 'suf5Next=.', 'suf4Next=.', 'suf3Next=.', 'suf2Next=.']\n",
      "['form=.', 'suf5=.', 'suf4=.', 'suf3=.', 'suf2=.', 'pref5=.', 'pref4=.', 'pref3=.', 'pref2=.', 'CountNum=False', 'CountCaps=False', 'Hyphen=False', 'Parenth=False', 'formPrev=EMCYT', 'suf5Prev=EMCYT', 'suf4Prev=MCYT', 'suf3Prev=CYT', 'suf2Prev=YT', 'EoS']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## \"MAIN\"\n",
    "# process each file in directory\n",
    "for f in listdir(datadir)[:1] :\n",
    "   \n",
    "   # parse XML file, obtaining a DOM tree\n",
    "   tree = parse(datadir+\"/\"+f)\n",
    "   \n",
    "   # process each sentence in the file\n",
    "   sentences = tree.getElementsByTagName(\"sentence\")\n",
    "   for s in sentences :\n",
    "      sid = s.attributes[\"id\"].value   # get sentence id\n",
    "      spans = []\n",
    "      stext = s.attributes[\"text\"].value   # get sentence text\n",
    "      entities = s.getElementsByTagName(\"entity\")\n",
    "      for e in entities :\n",
    "         # for discontinuous entities, we only get the first span\n",
    "         # (will not work, but there are few of them)\n",
    "         (start,end) = e.attributes[\"charOffset\"].value.split(\";\")[0].split(\"-\")\n",
    "         typ =  e.attributes[\"type\"].value\n",
    "         spans.append((int(start),int(end),typ))\n",
    "         \n",
    "\n",
    "      # convert the sentence to a list of tokens\n",
    "      tokens = tokenize(stext)\n",
    "      # extract sentence features\n",
    "      features = extract_features(tokens)\n",
    "      print(stext)\n",
    "      [print(x) for x in features]\n",
    "      #[print(len(x)) for x in features]\n",
    "\n",
    "      # print features in format expected by crfsuite trainer\n",
    "      for i in range (0,len(tokens)) :\n",
    "         # see if the token is part of an entity\n",
    "         tag = get_tag(tokens[i], spans) \n",
    "         #print (sid, tokens[i][0], tokens[i][1], tokens[i][2], tag, \"\\t\".join(features[i]), sep='\\t')\n",
    "\n",
    "      # blank line to separate sentences\n",
    "      print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6858c3dbc49267e902ff986705b591b9d7b57befff84fd7d814fe16c4a8e1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('ci_covid')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
